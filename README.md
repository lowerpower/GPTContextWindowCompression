# GPTContextWindowCompression
Loadable into your ChatGPT memory, utilities to compress your context window to make it usable forever

# üß© Context Compression Menu (GPT-5)
**Version:** 1.2 ‚Ä¢ **Status:** Stable

## Overview
GPT-5 context windows bloat fast (images, long chats, code drafts, pasted docs).  
This menu gives you quick commands to compress on the fly while preserving useful state.

**What‚Äôs new (v1.2)**
- ‚úÖ **Image ‚ÄúLite‚Äù representation** (summary + labels + scene graph + micro Q/A + OCR) ‚Äî all text, still tiny, much more searchable
- ‚úÖ **Export: context** command (JSON/Markdown snapshot before you compress)
- ‚úÖ Smarter defaults: **Compact + Lite** for images; batch all images; savings report after each run

---

## Quick Start
- Set defaults once (optional):  
  `Default images = Compact representation=lite; conversation = 400 tokens; notes = JSON`
- Use the one-liner:  
  `Compress: all`

---

## Commands

### Images
`Compress: images [Ultra | Compact | Verbose] [representation=summary|lite|full] [max_labels=8] [max_triples=8] [max_qa=6] [include_ocr=true|false]`  
- **Default:** `Compact representation=lite max_labels=8 max_triples=8 max_qa=6 include_ocr=true`  
- **Behavior:** Processes **all images in the conversation**; replaces heavy image tokens with text outputs.  
- **Representations:**
  - `summary` ‚Üí prose only (Ultra/Compact/Verbose)
  - `lite` ‚Üí prose **+** labels, small scene graph, micro Q/A, OCR (text-only)
  - `full` ‚Üí *offline only* (embeddings, pHash, ANN index; not in ChatGPT UI)
- **Savings vs ~3k-token image:**  
  - Ultra (~40): ~99%  
  - Compact (~400): ~85‚Äì90%  
  - Compact+Lite (~480‚Äì550): ~82‚Äì85%

### Conversation
`Compress: conversation [target=N tokens]`  
- **Default:** `400`  
- Rolls entire chat into a concise synopsis (goals, facts, decisions, TODOs).

### Code
`Compress: code`  
- Collapses drafts ‚Üí **final clean snippet** + **lessons learned**; drops intermediate attempts.

### Notes
`Compress: notes [JSON | bullets]`  
- **Default:** `JSON`  
- Converts brainstorms into compact schema grouped by topic.

### Document
`Compress: document [outline | summary | key points]`  
- **Default:** `outline`  
- Replaces long pasted docs with a structured abstract.

### Export (snapshot before trimming)
`Export: context [JSON | Markdown] [target=N tokens]`  
- **Default:** `JSON`  
- Creates a portable snapshot (conversation, images, notes, code). Optional token-capped export.

### All
`Compress: all`  
- Runs: Images ‚Üí **Compact+Lite**, Conversation ‚Üí **400**, Code ‚Üí **final+lessons**, Notes ‚Üí **JSON**.  
- Emits an **estimated token savings report**.

---

## Token Savings (Typical)

| Item                      | Before (tokens) | After (tokens) | % Saved |
|--------------------------|------------------|----------------|---------|
| Image (raw encoding)     | ~3,000           | Ultra ~40      | ~99%    |
|                          |                  | Compact ~400   | ~85‚Äì90% |
|                          |                  | Compact+Lite ~500 | ~82‚Äì85% |
| Conversation long ‚Üí 400  | 6‚Äì10k ‚Üí 400      | ~90%           |
| Notes ‚Üí JSON             | variable         | ~¬Ω‚Äì¬º size      | ~50‚Äì75% |

---

## Outputs

**Image (Lite) example**
```json
{
  "type": "image_card_lite",
  "version": "1.0",
  "id": "auto-or-your-handle",
  "source_hint": "filename-or-caption",
  "alt": "One-sentence alt text",
  "captions": { "ultra": "‚â§40 tokens", "compact": "‚âà400 tokens" },
  "labels": ["hat","scarf","wooden-frame","desert","mountains"],
  "scene_graph": [
    ["person-left","wears","wide-brim hat"],
    ["person-center","wears","orange scarf"],
    ["structure","stands-in","desert"]
  ],
  "qa": [
    {"q":"How many people?","a":"3"},
    {"q":"Environment?","a":"Desert with wooden frame and mountains"}
  ],
  "ocr": {"text": ""}
}

** Conversation summary output (400 tokens target) **
{
  "type": "conversation_summary",
  "version": "1.0",
  "goals": ["..."],
  "facts": ["..."],
  "decisions": ["..."],
  "constraints": ["..."],
  "todos": ["..."],
  "open_questions": ["..."]
}

** Export snapshot **
{
  "type": "context_snapshot",
  "version": "1.0",
  "timestamp": "ISO8601",
  "conversation_summary": { "tokens_estimated": 0, "goals": [], "facts": [], "decisions": [] },
  "images": [{ "id": "image-label", "raw_tokens_estimated": 3000, "summary_compact": "..." }],
  "notes": [{"topic": "Topic","points":["p1","p2"]}],
  "code_snippets": [{"final": "snippet","drafts_count": 0}]
}

Examples

Default daily driver:
Compress: images Compact representation=lite

Super lean for many photos:
Compress: images Ultra representation=lite max_labels=5 max_triples=5 max_qa=3

Conversation reset:
Compress: conversation 250

Everything at once (with snapshot):
Export: context JSON ‚Üí Compress: all

Best Practices

Keep Compact+Lite as default ‚Äî tiny, searchable, precise.

Use Ultra when juggling lots of images.

Keep Verbose out of the live window; archive it to files if needed.

Export before major compression if you want an audit trail.



